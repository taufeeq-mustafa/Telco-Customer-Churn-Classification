# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TgO1PJZ2y2p-zZrvK0Mfw6c2x16AX_2D
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from google.colab import drive

# Load data
drive.mount('/content/drive')
df = pd.read_csv("/content/drive/MyDrive/WA_Fn-UseC_-Telco-Customer-Churn.csv")


print(df.head())
print(df.info()) 
print(df["Churn"].value_counts())  


sns.countplot(x="Churn", data=df)
plt.title("Churn Distribution")
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer


df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")
df["TotalCharges"].fillna(df["TotalCharges"].median(), inplace=True)


X = df.drop("Churn", axis=1)
y = df["Churn"].apply(lambda x: 1 if x == "Yes" else 0)  


numeric_features = ["tenure", "MonthlyCharges", "TotalCharges"]
categorical_features = ["Contract", "PaymentMethod", "gender"]  

preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), numeric_features),
        ("cat", OneHotEncoder(), categorical_features)
    ])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, roc_auc_score

models = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(),
    "XGBoost": XGBClassifier()
}

for name, model in models.items():
    model.fit(X_train_resampled, y_train_resampled)
    y_pred = model.predict(X_test_processed)
    print(f"----- {name} -----")
    print(classification_report(y_test, y_pred))
    print(f"ROC-AUC: {roc_auc_score(y_test, y_pred)}\n")

from sklearn.model_selection import GridSearchCV

params = {
    "learning_rate": [0.01, 0.1],
    "max_depth": [3, 5],
    "scale_pos_weight": [1, 5]  
}

xgb = XGBClassifier()
grid_search = GridSearchCV(xgb, params, cv=3, scoring="roc_auc")
grid_search.fit(X_train_resampled, y_train_resampled)

print("Best params:", grid_search.best_params_)
best_model = grid_search.best_estimator_

import shap

explainer = shap.TreeExplainer(best_model)
shap_values = explainer.shap_values(X_test_processed[:100])  
s
shap.summary_plot(
    shap_values,
    X_test_processed[:100],
    feature_names=preprocessor.get_feature_names_out()
)